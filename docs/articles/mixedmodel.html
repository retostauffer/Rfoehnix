<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title> â€¢ foehnix</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<script src="../extra.js"></script><meta property="og:title" content="">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">foehnix</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1.6</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    How To

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/ellboegen.html">[Demo] EllbÃ¶gen (Tyrol, A)</a>
    </li>
    <li>
      <a href="../articles/viejas.html">[Demo] Viejas (California, USA)</a>
    </li>
    <li>
      <a href="../articles/windrose.html">[Plot] Wind Rose</a>
    </li>
    <li>
      <a href="../articles/tsplot.html">[Plot] Time Series</a>
    </li>
    <li>
      <a href="../articles/image.html">[Plot] HovmÃ¶ller Diagram</a>
    </li>
    <li>
      <a href="../articles/import_data.html">Import Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Advanced

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/mixedmodel.html">Statistical Model</a>
    </li>
    <li>
      <a href="../articles/logisticregression.html">Logistic Regression (IWLS)</a>
    </li>
    <li>
      <a href="../articles/inference.html">Inference</a>
    </li>
    <li>
      <a href="../articles/advanced_simulation.html">Censoring and Truncation</a>
    </li>
    <li>
      <a href="../articles/simulation.html">Verification with Simulated Data</a>
    </li>
    <li>
      <a href="../articles/families.html">foehnix Families</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/retostauffer/Rfoehnix/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip></h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/retostauffer/Rfoehnix/blob/HEAD/vignettes/mixedmodel.Rmd" class="external-link"><code>vignettes/mixedmodel.Rmd</code></a></small>
      <div class="hidden name"><code>mixedmodel.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="statistical-model">Statistical Model<a class="anchor" aria-label="anchor" href="#statistical-model"></a>
</h2>
<p>The automated foehn classification <code>foehnix</code> is based on a
two-component mixture model. The basic idea is that two unobservable
components (or clusters) exist. One component for situations without
foehn, one component for situations with foehn. <code>foehnix</code>
uses an unsupervised statistical method to identify the two components
based on a set of observed values (e.g., wind speed, gust speed,
potential temperature differences) to model the probability whether or
not a specific observation is related to a foehn event.</p>
<p>The statistical model consists of two parts: one part to identify the
two components, and a second part modelling the probability whether or
not a specific observation belongs to component 1 or component 2. The
latter is known as the <em>concomitant model</em>.</p>
<p>The density of a two-component mixed distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>â€¦</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">h(\dots)</annotation></semantics></math>
in its general form is specified as follows for a specific observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mi>ğ‘¥</mi><mi>i</mi></msub><mo>,</mo><mi>ğœƒ</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><munder><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ğ‘¥</mi><mi>i</mi></msub><mo>,</mo><mi>Î±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mi>ğœƒ</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="true">âŸ</mo></munder><mtext mathvariant="normal">component 1</mtext></munder><mo>+</mo><munder><munder><mrow><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ğ‘¥</mi><mi>i</mi></msub><mo>,</mo><mi>Î±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><msub><mi>ğœƒ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="true">âŸ</mo></munder><mtext mathvariant="normal">component 2</mtext></munder></mrow><annotation encoding="application/x-tex">h(y_i, \mathit{x}_i, \mathit{\theta}, \mathit{\alpha}) = \underbrace{(1 - \pi(\mathit{x}_i, \alpha)) \cdot f(y_i, \mathit{\theta}_1)}_{\text{component 1}} + \underbrace{\pi(\mathit{x}_i, \alpha) \cdot f(y_i, \mathit{\theta}_2)}_{\text{component 2}}</annotation></semantics></math></li>
</ul>
<p>â€¦ where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ‘¦</mi><annotation encoding="application/x-tex">\mathit{y}</annotation></semantics></math>
is the covariate for the first part of the statistical model to identify
components 1 and 2, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ±</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math>
the covariates for the concomitant model. The density of the mixed
distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>
is the sum (or superposition) of the densities of the two components
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>;
i.e., Gaussian distribution) times the probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Ï€</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>
from the concomitant model which describes whether or not a specific
observation belongs to component 2.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğœƒ</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ğœƒ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>ğœƒ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathit{\theta} = (\mathit{\theta}_1, \mathit{\theta}_2)</annotation></semantics></math>
are the distribution parameters of the components,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›¼</mi><annotation encoding="application/x-tex">\mathit{\alpha}</annotation></semantics></math>
the parameters of the concomitant model.</p>
<p>The concomitant model can be any model which fulfills
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Ï€</mi><mo>âˆˆ</mo><mspace width="0.222em"></mspace><mo stretchy="false" form="postfix">]</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="prefix">[</mo></mrow><annotation encoding="application/x-tex">\pi \in~]0,1[</annotation></semantics></math>,
e.g., an constant value or intercept only model (mixture model
<em>without concomitants</em>), or any kind of probability model.
<code>foehnix</code> uses a logistic regression model of the following
form:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">(</mo><mfrac><mi>Ï€</mi><mrow><mn>1</mn><mo>âˆ’</mo><mi>Ï€</mi></mrow></mfrac><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">)</mo><mo>=</mo><msup><mi>ğ±</mi><mi>âŠ¤</mi></msup><mi>ğ›¼</mi><mo>;</mo><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mi>Ï€</mi><mo>=</mo><mfrac><mrow><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ±</mi><mi>âŠ¤</mi></msup><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mn>1</mn><mo>+</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ±</mi><mi>âŠ¤</mi></msup><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\log\big(\frac{\pi}{1 - \pi}\big) = \mathbf{x}^\top \mathit{\alpha};~~ \pi = \frac{\exp(\mathbf{x}^\top \mathit{\alpha})}{1 + \exp(\mathbf{x}^\top \mathit{\alpha})}</annotation></semantics></math></li>
</ul>
<p>The final <em>foehn</em> probability of the two-component mixture
model, also known as the a-posteriori probability, is given by:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><mi>ğ±</mi><mo>,</mo><mi>ğœƒ</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>,</mo><msub><mi>ğ›‰</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>,</mo><msub><mi>ğ›‰</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.222em"></mspace><mo>+</mo><mspace width="0.222em"></mspace><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>,</mo><msub><mi>ğ›‰</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{\mathit{p}}(\mathit{y}, \mathbf{x}, \mathit{\theta}, \mathit{\alpha}) = \frac{\pi(\mathbf{x}, \mathit{\alpha}) \cdot f(\mathbf{y}, \mathbf{\theta}_2)}{  (1 - \pi(\mathbf{x}, \mathit{\alpha})) \cdot f(\mathbf{y}, \mathbf{\theta}_1) ~+~  \pi(\mathbf{x}, \mathit{\alpha}) \cdot f(\mathbf{y}, \mathbf{\theta}_2) }</annotation></semantics></math></li>
</ul>
<p>â€¦ where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><annotation encoding="application/x-tex">\hat{\mathit{p}}</annotation></semantics></math>
in our case represents the probability of foehn. All one has to know are
the parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğœƒ</mi><annotation encoding="application/x-tex">\mathit{\theta}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›¼</mi><annotation encoding="application/x-tex">\mathit{\alpha}</annotation></semantics></math>
which can be estimated using an appropriate M-estimator such as maximum
likelihood.</p>
</div>
<div class="section level2">
<h2 id="parameter-estimation">Parameter Estimation<a class="anchor" aria-label="anchor" href="#parameter-estimation"></a>
</h2>
<p>The maximum likelihood of a mixture model can usually not be
maximized directly. One possibility to estimate the coefficients of is
an iterative <em>expectation maximization</em> (EM) algorithm. The EM
algorithm otimizes the following log-likelihood:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>â„“</mo><mo>=</mo><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">(</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msub><mi>ğœƒ</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mo>â‹…</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msub><mi>ğœƒ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mo>â‹…</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mo>â‹…</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\ell = \sum_{i=1}^N \big(  (1 - \hat{\mathit{p}}) \cdot \log(f(\mathit{y}, \mathit{\theta}_1)) +  \hat{\mathit{p}} \cdot \log(f(\mathit{y}, \mathit{\theta}_2)) +  (1 - \hat{\mathit{p}} \cdot \log(1 - \mathit{\pi}(\mathbf{x}, \mathit{\alpha})) +  \hat{\mathit{p}} \cdot \log(\mathit{\pi}(\mathbf{x}, \mathit{\alpha})) \big)</annotation></semantics></math>.</li>
</ul>
<p>with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><annotation encoding="application/x-tex">\hat{\mathit{p}}</annotation></semantics></math>
as specified above (a-posteriori probability).
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
represents the number of observations.</p>
<p>The EM algorithm is specified as follows:</p>
<ul>
<li><p><strong>Initialization:</strong> initialize values for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›‰</mi><annotation encoding="application/x-tex">\mathbf{\theta}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›¼</mi><annotation encoding="application/x-tex">\mathit{\alpha}</annotation></semantics></math>.</p></li>
<li><p><strong>Estimation:</strong> compute the posterior class
probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><mi>ğ±</mi><mo>,</mo><mi>ğœƒ</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\mathit{p}}(\mathit{y}, \mathbf{x}, \mathit{\theta}, \mathit{\alpha})</annotation></semantics></math></p></li>
<li><p><strong>Maximize:</strong> estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğœƒ</mi><annotation encoding="application/x-tex">\mathit{\theta}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›¼</mi><annotation encoding="application/x-tex">\mathit{\alpha}</annotation></semantics></math>
which maximize the likelihood using the posterior class probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><annotation encoding="application/x-tex">\hat{\mathit{p}}</annotation></semantics></math>
from the estimation step as weights:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><mi>ğ±</mi><mo>,</mo><mi>ğœƒ</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>,</mo><msub><mi>ğ›‰</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>,</mo><msub><mi>ğ›‰</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ±</mi><mo>,</mo><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>,</mo><msub><mi>ğ›‰</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{\mathit{p}}(\mathit{y}, \mathbf{x}, \mathit{\theta}, \mathit{\alpha}) =  \frac{\hat{p}(\mathbf{x}, \mathit{\alpha}) \cdot f(\mathbf{y}, \mathbf{\theta}_2)}{  (1 - \hat{p}(\mathbf{x}, \mathit{\alpha})) \cdot f(\mathbf{y}, \mathbf{\theta}_1) +  \hat{p}(\mathbf{x}, \mathit{\alpha}) \cdot f(\mathbf{y}, \mathbf{\theta}_2)  }</annotation></semantics></math></p></li>
</ul>
<p>The EM steps are repeated until the likelihood improvement falls
below a certain threshold or the maximum number of iterations is
reached.</p>
</div>
<div class="section level2">
<h2 id="gaussian-mixture-model-without-concomitants">Gaussian Mixture Model Without Concomitants<a class="anchor" aria-label="anchor" href="#gaussian-mixture-model-without-concomitants"></a>
</h2>
<p>The simplest case is a Gaussian two-component mixture model without
concomitants. In this case the density of the two components is the
density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Ï•</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
of the Gaussian distribution with its parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğœƒ</mi><mn>1</mn></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Î¼</mi><mn>1</mn></msub><mo>,</mo><msub><mi>Ïƒ</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathit{\theta}_1 = (\mu_1, \sigma_1)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğœƒ</mi><mn>2</mn></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Î¼</mi><mn>2</mn></msub><mo>,</mo><msub><mi>Ïƒ</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathit{\theta}_2 = (\mu_2, \sigma_2)</annotation></semantics></math>
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î¼</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Ïƒ</mi><annotation encoding="application/x-tex">\sigma</annotation></semantics></math>
are the <em>location</em> and <em>scale parameter</em> of the Gaussian
distribution, or <em>mean</em> and <em>standard deviation</em>.</p>
<div class="section level4">
<h4 id="initialization-step">Initialization step<a class="anchor" aria-label="anchor" href="#initialization-step"></a>
</h4>
<p>First, initial values for the parameters
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğœƒ</mi><annotation encoding="application/x-tex">\mathit{\theta}</annotation></semantics></math>)
and the posterior weights
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><annotation encoding="application/x-tex">\hat{\mathit{p}}</annotation></semantics></math>)
have to be specified.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›¼</mi><annotation encoding="application/x-tex">\mathit{\alpha}</annotation></semantics></math>
does not have to be initialized as no concomitant model is used in this
case! To be able to do so we have to attribute each observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ğ‘¦</mi><mi>i</mi></msub><mo>âˆ€</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>â€¦</mi><mo>,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">\mathit{y}_i \forall i = 1, \dots, N</annotation></semantics></math>
to one of the two components. This initial membership will be denoted as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ‘§</mi><annotation encoding="application/x-tex">\mathit{z}</annotation></semantics></math>
and takes 1 if observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
belongs to <em>component 2</em> and 0 else. This initial attribution
defines that observations with high values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ‘¦</mi><annotation encoding="application/x-tex">\mathit{y}</annotation></semantics></math>
belong to component 2, observations with low values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ‘¦</mi><annotation encoding="application/x-tex">\mathit{y}</annotation></semantics></math>
to component 1.</p>
<p><strong>Note:</strong> Depending on the model specification this can
lead to models where the probability for <em>no foehn</em> will be
returned by <code>foehnix</code> rather than posteriori probability of
<em>foehn</em>. However, the <code>switch</code> argument of the
<code>foehnix(...)</code> function allows you to control this behavior
(see <a href="reference/foehnix.html"><code>foehnix</code> manual
page</a>).</p>
<p><code>foehnix</code> uses the following initialization for the
two-component Gaussian mixture model without concomitants:</p>
<ol style="list-style-type: decimal">
<li>Initialize class membership:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mrow><mo stretchy="true" form="prefix">{</mo><mtable><mtr><mtd columnalign="left" style="text-align: left"><mn>1</mn></mtd><mtd columnalign="left" style="text-align: left"><mtext mathvariant="normal">if</mtext><mspace width="0.222em"></mspace><msub><mi>y</mi><mi>i</mi></msub><mo>â‰¥</mo><mover><mi>y</mi><mo accent="true">â€¾</mo></mover></mtd></mtr><mtr><mtd columnalign="left" style="text-align: left"><mn>0</mn></mtd><mtd columnalign="left" style="text-align: left"><mtext mathvariant="normal">else</mtext></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">z_i = \begin{cases}1 &amp; \text{if}~y_i \ge \bar{y} \\ 0 &amp; \text{else}\end{cases}</annotation></semantics></math>
</li>
<li>Initial parameters for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ›‰</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathbf{\theta}^{(0)}</annotation></semantics></math>
using weighted empirical moments for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Î¼</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\mu_1</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Î¼</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\mu_2</annotation></semantics></math>
and the standard deviation of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
as initial guess for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ïƒ</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\sigma_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ïƒ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\sigma_2</annotation></semantics></math>:
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Î¼</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu_1^{(0)} = \frac{1}{\sum_{i=1}^{N} (1-z_i)} \sum_{i=1}^{N} (1-z_i) \cdot y_i</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Î¼</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>z</mi><mi>i</mi></msub></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>z</mi><mi>i</mi></msub><mo>â‹…</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu_2^{(0)} = \frac{1}{\sum_{i=1}^{N} z_i} \sum_{i=1}^{N} z_i \cdot y_i</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Ïƒ</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><msubsup><mi>Ïƒ</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mo minsize="1.2" maxsize="1.2" stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><mover><mi>y</mi><mo accent="true">â€¾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msup><mo minsize="1.2" maxsize="1.2" stretchy="false" form="postfix">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mrow><annotation encoding="application/x-tex">\sigma_1^{(0)} = \sigma_2^{(0)} = \big(\frac{1}{N} \sum_{i=1}^{N} (y_i - \bar{y})^2\big)^\frac{1}{2}</annotation></semantics></math></li>
</ul>
</li>
<li>Initialize
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\mathit{\pi}^{(0)} = 0.5</annotation></semantics></math>
</li>
<li>Given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğœƒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathit{\theta}^{(0)}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathit{\pi}^{(0)}</annotation></semantics></math>:
calculate a-posteriory probability:
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mfrac><mrow><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>â‹…</mo><mi>Ï•</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msubsup><mi>ğœƒ</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>Ï•</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msubsup><mi>ğœƒ</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>â‹…</mo><mi>Ï•</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msubsup><mi>ğœƒ</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{\mathit{p}}^{(0)} = \frac{\mathit{\pi}^{(0)} \cdot \phi(\mathit{y}, \mathit{\theta}_2^{(0)})}{  (1 - \mathit{\pi}^{(0)}) \cdot \phi(\mathit{y}, \mathit{\theta}_1^{(0)})  + \mathit{\pi}^{(0)} \cdot \phi(\mathit{y}, \mathit{\theta}_2^{(0)})}</annotation></semantics></math></li>
</ul>
</li>
</ol>
<p>Once the required elements have been initialized start the EM
algorithm for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi>i</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">j = 1, ..., maxit</annotation></semantics></math>:</p>
<ol start="5" style="list-style-type: decimal">
<li>Update
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mtext mathvariant="normal">mean</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi^{(j)} = \text{mean}(\hat{\mathit{p}}^{(j-1)})</annotation></semantics></math>
</li>
<li>Obtain new
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğœƒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathit{\theta}^{(j)}</annotation></semantics></math>
using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\hat{\mathit{p}}^{(j-1)}</annotation></semantics></math>:
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Î¼</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msubsup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu_1^{(j)} = \frac{1}{\sum_{i=1}^{N} (1 - \hat{p}_i^{(j-1)})} \sum_{i=1}^{N} (1 - \hat{\mathit{p}}_i^{(j-1)}) \cdot y_i</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Î¼</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>â‹…</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu_2^{(j)} = \frac{1}{\sum_{i=1}^{N} \hat{p}_i^{(j-1)}} \sum_{i=1}^{N} \hat{\mathit{p}}_i^{(j-1)} \cdot y_i</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Ïƒ</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mo minsize="1.8" maxsize="1.8" stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><mover><mi>y</mi><mo accent="true">â€¾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msup><mo minsize="1.8" maxsize="1.8" stretchy="false" form="postfix">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mrow><annotation encoding="application/x-tex">\sigma_1^{(j)} = \Big(\frac{1}{\sum_{i=1}^{N} (1-\hat{p}_i^{(j-1)})} \sum_{i=1}^{N} (1 - \hat{p}_i^{(j-1)}) \cdot (y_i - \bar{y})^2\Big)^\frac{1}{2}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Ïƒ</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mo minsize="1.8" maxsize="1.8" stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>â‹…</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><mover><mi>y</mi><mo accent="true">â€¾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msup><mo minsize="1.8" maxsize="1.8" stretchy="false" form="postfix">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mrow><annotation encoding="application/x-tex">\sigma_2^{(j)} = \Big(\frac{1}{\sum_{i=1}^{N} \hat{p}_i^{(j-1)}} \sum_{i=1}^{N} \hat{p}_i^{(j-1)} \cdot (y_i - \bar{y})^2\Big)^\frac{1}{2}</annotation></semantics></math></li>
</ul>
</li>
<li>Update posterior probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\hat{\mathit{p}}^{(j)}</annotation></semantics></math>:
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mfrac><mrow><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>â‹…</mo><mi>Ï•</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msubsup><mi>ğœƒ</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><mi>Ï•</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msubsup><mi>ğœƒ</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>â‹…</mo><mi>Ï•</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ‘¦</mi><mo>,</mo><msubsup><mi>ğœƒ</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\hat{\mathit{p}}^{(j)} = \frac{\mathit{\pi}^{(j)} \cdot \phi(\mathit{y}, \mathit{\theta}_2^{(j)})}{(1 - \mathit{\pi}^{(j)}) \cdot \phi(\mathit{y}, \mathit{\theta}_1^{(j)}) + \mathit{\pi}^{(j)} \cdot \phi(\mathit{y}, \mathit{\theta}_2^{(j)})}</annotation></semantics></math></li>
</ul>
</li>
<li>Calculate likelihood:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mo>â„“</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\ell^{(j)}</annotation></semantics></math>.
If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">j = 1</annotation></semantics></math>
proceed with <strong>step 5</strong>.</li>
<li>For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">j &gt; 1</annotation></semantics></math>:
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msup><mo>â„“</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>âˆ’</mo><msup><mo>â„“</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>&lt;</mo><mtext mathvariant="normal">tol</mtext></mrow><annotation encoding="application/x-tex">(\ell^{(j)} - \ell^{(j-1)}) &lt; \text{tol}</annotation></semantics></math>
the likelihood could not have been improved in iteration
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
(converged or stuck): stop EM algorithm and return parameters of
iteration
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>âˆ’</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">j-1</annotation></semantics></math>.
If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mtext mathvariant="normal">maxit</mtext></mrow><annotation encoding="application/x-tex">j = \text{maxit}</annotation></semantics></math>:
maximum number of iterations reached, stop EM algorithm, return
parameters of iteration
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.
Else proceed with <strong>step 5</strong> until one of the stopping
criteria is reached.</li>
</ol>
</div>
</div>
<div class="section level2">
<h2 id="gaussian-mixture-model-with-concomitants">Gaussian Mixture Model With Concomitants<a class="anchor" aria-label="anchor" href="#gaussian-mixture-model-with-concomitants"></a>
</h2>
<p>The optimizer for a two-component Gaussian mixture model with
additional concomitants is very similar except that we also have to
update the concomitant model (logistic regression model). For mixed
models with concomitants the probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğœ‹</mi><annotation encoding="application/x-tex">\mathit{\pi}</annotation></semantics></math>
are a function of the concomitant covariates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ±</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math>
and the regression coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ›¼</mi><annotation encoding="application/x-tex">\mathit{\alpha}</annotation></semantics></math>.</p>
<p>The following algorithm is used:</p>
<ol style="list-style-type: decimal">
<li>Initialize class membership
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ‘§</mi><annotation encoding="application/x-tex">\mathit{z}</annotation></semantics></math><em>as for the Gaussian mixture model without concomitants</em>.</li>
<li>Initialize coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğœƒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathit{\theta}^{(0)}</annotation></semantics></math><em>as for the Gaussian mixture model without concomitants</em>.</li>
<li>Given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ‘§</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathit{z}^{(0)}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ±</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math>:
estimate logistic regression model to obtain the parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğ›¼</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathit{\alpha}^{(0)}</annotation></semantics></math>,
calculate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>ğœ‹</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><mfrac><mrow><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ±</mi><mi>âŠ¤</mi></msup><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mn>1</mn><mo>+</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ±</mi><mi>âŠ¤</mi></msup><mi>ğ›¼</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">\mathit{\pi}^{(0)} = \frac{\exp(\mathbf{x}^\top \mathit{\alpha})}{1 + \exp(\mathbf{x}^\top \mathit{\alpha})}</annotation></semantics></math>
(see <a href="logisticregression.html">logistic regression</a>
vignette).</li>
<li>Calculate a-posteriori probability
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\hat{\mathit{p}}^{(0)}</annotation></semantics></math><em>as for the Gaussian mixture model without concomitants</em>.</li>
</ol>
<p>The EM algorithm for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>â€¦</mi><mo>,</mo><mtext mathvariant="normal">maxit</mtext></mrow><annotation encoding="application/x-tex">j = 1, \dots, \text{maxit}</annotation></semantics></math>:</p>
<ol start="5" style="list-style-type: decimal">
<li>Update
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Ï€</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\pi^{(j)}</annotation></semantics></math>
by updating the concomitant model (logistic regression model) using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\hat{\mathit{p}}^{(j-1)}</annotation></semantics></math>
as response for the concomitant model (see <a href="logisticregression.html">logistic regression</a> vignette).</li>
<li>Obtain new
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ğœƒ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\mathit{\theta}^{(j)}</annotation></semantics></math><em>as for the Gaussian mixture model without concomitants</em>.</li>
<li>Update posterior probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>ğ‘</mi><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><annotation encoding="application/x-tex">\hat{\mathit{p}}^{(j)}</annotation></semantics></math><em>as for the Gaussian mixture model without concomitants</em>.</li>
<li>Calculate likelihood <em>as for the Gaussian mixture model without
concomitants</em>.</li>
<li>
<em>As for the Gaussian mixture model without concomitants</em>:
proceed with <strong>step 5</strong> until one of the stopping criteria
is reached.</li>
</ol>
</div>
<div class="section level2">
<h2 id="logistic-mixture-model">Logistic Mixture Model<a class="anchor" aria-label="anchor" href="#logistic-mixture-model"></a>
</h2>
<p>The logistic two-component mixture models can be estimated as the
Gaussian ones except that component density is the density of the
logistic distribution, and that the weighted empirical moments for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ïƒ</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\sigma_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ïƒ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\sigma_2</annotation></semantics></math>,
the scale of the logistic distribution, is now:</p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Ïƒ</mi><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mo minsize="1.8" maxsize="1.8" stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>âˆ’</mo><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mo>â‹…</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><mover><mi>y</mi><mo accent="true">â€¾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msup><mo minsize="1.8" maxsize="1.8" stretchy="false" form="postfix">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo>â‹…</mo><mfrac><msqrt><mn>3</mn></msqrt><mn>3.1415</mn></mfrac></mrow><annotation encoding="application/x-tex">\sigma_1^{(j)} = \Big(\frac{1}{\sum_{i=1}^{N} (1-\hat{p}_i^{(j-1)})} \sum_{i=1}^{N} (1 - \hat{p}_i^{(j-1)}) \cdot (y_i - \bar{y})^2\Big)^\frac{1}{2} \cdot \frac{\sqrt{3}}{3.1415}</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Ïƒ</mi><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mo minsize="1.8" maxsize="1.8" stretchy="false" form="prefix">(</mo><mfrac><mn>1</mn><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup></mrow></mfrac><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mover><mi>p</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>âˆ’</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>â‹…</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>âˆ’</mo><mover><mi>y</mi><mo accent="true">â€¾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msup><mo minsize="1.8" maxsize="1.8" stretchy="false" form="postfix">)</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo>â‹…</mo><mfrac><msqrt><mn>3</mn></msqrt><mn>3.1415</mn></mfrac></mrow><annotation encoding="application/x-tex">\sigma_2^{(j)} = \Big(\frac{1}{\sum_{i=1}^{N} \hat{p}_i^{(j-1)}} \sum_{i=1}^{N} \hat{p}_i^{(j-1)} \cdot (y_i - \bar{y})^2\Big)^\frac{1}{2} \cdot \frac{\sqrt{3}}{3.1415}</annotation></semantics></math></li>
</ul>
</div>
<div class="section level2">
<h2 id="censored-and-truncated-models">Censored and Truncated Models<a class="anchor" aria-label="anchor" href="#censored-and-truncated-models"></a>
</h2>
<p>In case of a censored or truncated mixed model the distributional
parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğœƒ</mi><annotation encoding="application/x-tex">\mathit{\theta}</annotation></semantics></math>
of the components of the mixture model cannot be calculated using
weighted empirical moments. In these cases a numreical likelihood-based
solver is used to estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Î¼</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\mu_1</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Î¼</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\mu_2</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ïƒ</mi><mn>1</mn></msub><annotation encoding="application/x-tex">\sigma_1</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Ïƒ</mi><mn>2</mn></msub><annotation encoding="application/x-tex">\sigma_2</annotation></semantics></math>.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Reto Stauffer.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

      </footer>
</div>






  </body>
</html>
